%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% 
% Generic template for TFC/TFM/TFG/Tesis
% 
% By:
% + Javier Macías-Guarasa. 
% Departamento de Electrónica
% Universidad de Alcalá
% + Roberto Barra-Chicote. 
% Departamento de Ingeniería Electrónica
% Universidad Politécnica de Madrid   
% 
% Based on original sources by Roberto Barra, Manuel Ocaña, Jesús Nuevo,
% Pedro Revenga, Fernando Herránz and Noelia Hernández. Thanks a lot to
% all of them, and to the many anonymous contributors found (thanks to
% google) that provided help in setting all this up.
% 
% See also the additionalContributors.txt file to check the name of
% additional contributors to this work.
% 
% If you think you can add pieces of relevant/useful examples,
% improvements, please contact us at (macias@depeca.uah.es)
% 
% You can freely use this template and please contribute with
% comments or suggestions!!!
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\chapter{Related Works}
\label{cha:related_works}

\begin{FraseCelebre}
\begin{Frase}
	Llegaré a ser el mejor, El mejor que habrá jamás \\
	Mi causa es ser su entrenador, Tras poderlos capturar.  
	
	Viajaré a cualquier lugar, Llegaré a cualquier rincón \\  
	Y al fin podré desentrañar, El poder de su interior.  
	
	¡Pokémon! Hazte con todos (solos tú y yo), \\
	Es mi destino, mi misión \\
	¡Pokémon! Tú eres mi amigo fiel, \\
	Nos debemos defender.
\end{Frase}
\begin{Fuente}
	Opening 1 de Pokémon: "Gotta catch 'em all!" \\
	Autor original: Jason Paige
\end{Fuente}
\end{FraseCelebre}

\section{Introduction}
\label{sec:2_introduction}

One of the crucial tasks that \acp{ADS} must face during navigation, specially in arbitrarily complex urban scenarios, is to predict the behaviour of dynamic obstacles \cite{chang2019argoverse, salzmann2020trajectron++}. In a similar way to humans that pay more attention to nearby obstacles and upcoming turns than considering the obstacles far away, the perception layer of an \ac{ADS} must focus more on the salient regions of the scene, particularly on the more relevant dynamic agents to predict their future behaviour before conducting a maneuver, such as lane changing or accelerating. 

Before proceeding with the study of the different methods of the \ac{SOTA} of \ac{MP} in the field of \ac{AD}, one important thing to note is that this thesis is focused on non-conditional motion prediction, also referred as \ac{PMP}, where the prediction of surrounding agents is not influenced by the future decisions of the ego-vehicle or even other agents, referred as \ac{CMP} in the literature. Most existing works \cite{gilles2021home, gilles2022gohome, varadarajan2022multipath++, wang2022ganet, schmidt2022crat, liang2020learning} focus on a passive prediction scheme, where the future states of a particular agent are predicted given its past information, other surrounding agents information and interactions as well as the physical context. Then, downstream planning modules, specially the behaviour planning module (also referred as \ac{DM} layer, as stated in Section \ref{sec:1_ad_architecture}) and the ego-vehicle (our vehicle) future actions are computed according to the predicted trajectories in a passive manner, that is, without modifying the output of the prediction model, and the global route previously calculated. 

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{chapter_2_related_works/cmp_vs_pmp.pdf}
	\caption[Example of a Conditional Motion Prediction (CMP) pipeline]{Example of a Conditional Motion Prediction (CMP) pipeline. We \textbf{\color{red}{highlight}} the influence of the \ac{ADS} in the prediction of surrounding agents.}
	\label{fig:chapter_2_related_works/cmp_vs_pmp}
\end{figure}

Nevertheless, to ensure safety under various predicted trajectories of the surrounding agents, our \ac{ADS} must overly conservative with inefficient maneuvers, specifically in arbitrarily complex traffic scenarios, because \ac{PMP} models ignore the fact that the future states of an agent can influence the future actions of other agents, what is the most realistic situation. Figure \ref{fig:chapter_2_related_works/cmp_vs_pmp} shows the differences between these two approaches. To this end, researchers recently started to explore a more coherent interactive prediction and planning framework which relies on predicting the surrounding agents future trajectories conditioned on the ego-vehicle future actions \cite{tang2019multiple} \cite{rhinehart2019precog} \cite{khandelwal2020if}, as a preliminary state to implement a fully-interaction graph where the future states of all agents (either autonomous prototypes or human-driven) influence in the decision of all agents. 

\begin{comment}
Under such frameworks, the \acs{ADS} can reason over potential actions while considering its influence on surrounding agents, as observed in Figure \ref{fig:chapter_2_related_works/cmp_vs_pmp}, inducing less conservative and more efficient maneuvers in highly interactive scenarios. \cite{huang2023conditional} propose a learning-based behaviour planning framework that learns to predict conditional multi-agent future trajectories, evaluating decisions from real-world human data. Moreover, they propose a two-stage learning process where the prediction model is trained first conditioned on the \ac{ADS} future actions, and then used as an environment model in the learning of the cost function with maximum entropy Inverse Reinforcement Learning (IRL). \cite{tang2022interventional} argue that CMP-based models essentially learns the posterior distribution of future trajectories conditioned on the future states of the ego-vehicle, where this future trajectory is treated as an observation, whilst safe and realistic prediction models should build the \ac{MP} to approximate the future trajectory distribution under the intervention of enforcing the \ac{ADS} future states, referring this new task as Interventional Behaviour Prediction (IBP). As aforementioned, the algorithms studied and developed throughout this thesis do not focus on the joint study of the prediction and behaviour planning modules, but on building efficient and powerful \ac{PMP} algorithms without considering the future states of the autonomous agents as an additional condition. 
\end{comment}
	
Once the differences between \ac{CMP} and \ac{PMP} have been illustrated, we proceed with the problem formulation, main contextual factors and classification of prediction methods.

\section{Problem Formulation of Motion Prediction}
\label{sec:2_problem_formulation_mp}

Given a sequence of past trajectories $a_{P}=[a_{-obs_{len}^{'}+1},a_{-obs_{len}^{'}+2},...,a_{0}]$ for an agent, we aim to predict its future steps $a_{F}=[a_{1},a_{2},...,a_{pred_{len}}]$ up to a fixed time step $pred_{len}$. Running in a specific traffic scenario, each agent will interact with static HD maps $m$ and the other dynamic actors, meeting the corresponding traffic and social rules. Therefore, the probabilistic distribution that we want to capture is $p(a_F|m, a_P, a^O_P)$, where $a^O_P$ denotes the other agents observed states. 

The output of most existing methods is a weighted set of trajectories $A_F = \{a_{F}^k\}_{k \in [0,K-1]}= \{(a_{1}^k,a_{2}^k,...,a_{pred_{len}}^k)\}_{k \in [0,K-1]}$ for each agent, where $K$ represents the number of modes or plausible future directions, due to the inherent uncertainty associated to the prediction problem. Note that the set is weighted since each mode will have an associated confidence or probability of occurrence, where the sum of all mode probabilities must be equal to 1. This weighted set of trajectories for each agent will be used by downstream decision modules. On top of that, TNT (Target-driven trajectory prediction) \cite{zhao2021tnt} is one of the first methods that introduces specific preliminary future positions in the problem formulation, also referred as goals, being TNT \cite{zhao2021tnt}-like methods distribution approximated as:

\begin{equation}
	\sum_{\tau \in T(m, a_P, a^O_P)}{p(\tau|m, a_P, a^O_P)p(a_F|\tau, m, a_P, a^O_P)}
\end{equation}

where $T(m, a_P, a^O_P)$ is the space of candidate goals depending on the driving context and $\tau$ a specific goal.

However, the map space $m$ is large, and the goal space $T(m, a_P, a^O_P)$ requires careful design. In that sense, some methods expect to accurately predict the actor motion by extracting good features. For example, LaneGCN \cite{liang2020learning} tries to approximate $p(a_F|m, a_P, a^O_P)$ by modeling $p(a_F|M_{a_0}, a_P, a^O_P)$, where $M_{a_0}$ is a "local" map features that is related to the actor's state $a_0$ at final observed step $t=0$.

To extract $M_{a_0}$, they use $a_0$ as an anchor to retrieve its surrounding map elements and aggregate their features. We found that not only the "local" map information is important, but also the goal area maps information is of great importance for accurate trajectory prediction. So, the probability can be reconstructed as:

\begin{equation}
	\sum _{\tau}{p(\tau|M_{a_0}, a_P, a^O_P) p(M_{\tau}|m, \tau)p(a_F|M_{\tau},M_{a_0}, a_P, a^O_P)}
\end{equation}

Then, in this work we aim to include preliminary heuristic information, as well as predict possible goals $\tau$ based on agents motion histories and driving context to retrieve the map elements in goal areas explicitly and aggregate their map features as $M_{\tau}$. to meet the requirements of the problem formulation. 

\section{Contextual Factors and Classification of Motion Prediction methods}
\label{sec:2_contextual_factors_and_classification_mp}

This section studies the contextual factors (inputs) and classification of \ac{MP} in the field of \ac{AD} according to its encoding method of the different inputs and output types. Figure \ref{fig:chapter_2_related_works/input_output_mp} summarizes the main inputs and outputs of these methods. 

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{chapter_2_related_works/inputs_outputs_mp.pdf}
	\caption{Contextual factors and output types in Vehicle Motion Prediction}
	Source: \textit{A survey on trajectory-prediction methods for autonomous driving} \cite{huang2022survey}
	\label{fig:chapter_2_related_works/input_output_mp}
\end{figure}

In order to model the future states of surrounding agents, \ac{MP} models must pay attention to the current environment, where some contextual factors can be clearly identified:

\begin{itemize}
	
	\item \textbf{Physics-related factors} refer to the kinematic and dynamic variables of the agents, specifically to their spatio-temporal variables (such as position, velocity, acceleration, object type or mass) as well as past behaviours. 
	
	\item \textbf{Interaction-related factors} include the inter-dependencies and social regulations between agents maneuvers. It is important to consider that traffic agents can be either non-relevant pedestrians on the sidewalk as well as an extremely relevant truck in front of the ego-vehicle.
	
	\item \textbf{Road-related factors} include the corresponding traffic rules (lane type, traffic signals, stops, etc.) as well as the modeling of the map (usually HD-map), including its topological, semantic and geometrical information.
	
\end{itemize}

On the other hand, regarding the output types, \ac{MP} methods need to provide the future trajectories of traffic participants. Nevertheless, these methods can provide these future trajectories in different ways, even though these outputs can be unified as a single output, depending on the application:

\begin{itemize}
	
	\item \textbf{Uni-modal prediction}: In the uni-modal case, the prediction method only returns a single future trajectory, without taking into account other possible behaviours. 
	
	\item \textbf{Multi-modal prediction}: Models that generate a multi-modal prediction compute multiple \textit{K} future trajectories (also referred as modes in the literature) with the probability of each future trajectory. The higher the mode probability (also referred as score), the more probable a particular future trajectory should be. Instead of providing a single trajectory, these models would generate a range of probable trajectories, considering different driving styles, intentions, and uncertainties. Multi-modal prediction can enable \ac{ADS} to anticipate and respond to a wider range of possible scenarios, enhancing safety and adaptability. This output type is specially useful for fast-changing and highly interactive situations where multiple options are available. One important thing to note is that multi-modal methods must be designed in order to not only reason in terms of different maneuvers (keep straight, turn right, lane change, etc.) but also different velocity profiles (constant velocity, acceleration, sudden break, etc.) regarding the same maneuver. This type of prediction will be the final objective throughout this thesis.
	
	\item \textbf{Intention}: Also referred as maneuver in the literature, the intention can be part of the final output or just be an intermediate step in the method. \ac{MP} methods usually produce maneuver intention (\ie \ a discrete space of actions, such as turn left, turn right, sudden acceleration, emergency break, and so forth and so on) to assist in the subsequent prediction. In the literature, the maneuver or behaviour is usually returned by a behavioural planner (\ac{DM}) module, while the specific future trajectory is usually returned by a \ac{MP} algorithm to compute the specific future steps of the agents.
\end{itemize}

As we will study throughout this section, most prediction methods focus on the multi-modal output with an associated probability for each mode, since this is the most realistic way to imitate the human brain during navigation. First of all, there are plenty of problems during navigation, since there is a high uncertainty of traffic behavior and a large number of different situations. That means that one cannot use a discrete number of situations and a discrete number of car movements. Second, the main tasks of \ac{ADS}, like ensuring safe and efficient operations and anticipating a multitude of possible behaviors of traffic actors in its surroundings, provide a large need in knowing the position of all vehicles beforehand. Multi-modal means that we have multiple predictions for each timeframe. 

Figure \ref{fig:chapter_2_related_works/um_vs_mm_mp} illustrates an interesting traffic scenario processed by one of our algorithms. The \textbf{\textcolor{YellowOrange}{target agent}} is getting close to an intersection, where several future maneuvers are plausible. In both cases (uni-modal and multi-modal, which are the most common ones), the model must reason the future trajectory of the target agent based on its past observations, interactions with other agents and physical context. On the left (\ref{subfig:chapter_2_related_works/um_vs_mm_mp_a}) illustrates the uni-modal case, where a single trajectory is predicted. On the right (\ref{subfig:chapter_2_related_works/um_vs_mm_mp_b}), multiple trajectories (or modes) with associated probabilities are predicted, with most modes turning left and one mode keeping straight since in similar situations the agent could also perform this behaviour with a similar context. As stated above, the main point of having this multi-modality is to compute different plausible options with an associated confidence. Note that lots of \ac{SOTA} algorithms study the problem of multi-modal predictions since similar past trajectories (\eg \ a vehicle stopped in front of an intersection) can produce totally different future trajectories (\eg \ turn left, turn right or keep straight).

\begin{figure}[t!]
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{chapter_2_related_works/mm_example_um.png}
		\caption{Uni-modal prediction}
		\label{subfig:chapter_2_related_works/um_vs_mm_mp_a}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{chapter_2_related_works/mm_example_mm.png}
		\caption{Multi-modal prediction}
		\label{subfig:chapter_2_related_works/um_vs_mm_mp_b}
	\end{subfigure}
	\captionsetup{justification=justified}
	\caption[Modeling uni-modality vs multi-modality of future $3$-second agent trajectories with one of our algorithms]{Modeling uni-modality vs multi-modality of future $3$-second agent trajectories with one of our algorithms; We represent: our vehicle (\textbf{\textcolor{blue}{ego}}), the \textbf{\textcolor{YellowOrange}{target agent}}, and \textbf{\textcolor{gray}{other agents}}. We can also see the \textbf{\textcolor{red}{ground-truth}} trajectory of the target agent, our \textbf{\textcolor{ForestGreen}{multi-modal predictions}} (with the corresponding confidences) for the target agent and \textbf{plausible centerlines}, also for the target agent in this algorithm. Circles represent last observations and diamonds last future positions.}
	\label{fig:chapter_2_related_works/um_vs_mm_mp}
\end{figure}

After defining the contextual factors and output types, a classification of the prediction methods according to different modeling approaches is illustrated. Over the last two decades, \ac{MP} can be divided into four parts in chronological order: Physics-based, classic \ac{ML}-based, \ac{RL}-based and \ac{DL}-based, as shown in Figure \ref{fig:chapter_2_related_works/taxonomy_mp}. The remaining content of this section, based on the study performed by \cite{huang2022survey}, illustrates the main algorithms used in this thesis, especially focusing on \ac{DL} since in this work we focus on predictive techniques for scene understanding based on deep models.

\begin{figure}[h]
	\centering
	% trim={left bottom right top}
	\includegraphics[trim={0 1cm 0 1cm}, width=\linewidth]{chapter_2_related_works/taxonomy_mp.pdf}
	\caption[Contextual factors and output types in Vehicle Motion Prediction]{Contextual factors and output types in Vehicle Motion Prediction. We \textcolor{magenta}{highlight} the main algorithms used in this thesis: Physics-based and Deep Learning based.}
	%Source: \textit{A survey on trajectory-prediction methods for autonomous driving} \cite{huang2022survey}
	\label{fig:chapter_2_related_works/taxonomy_mp}
\end{figure}

\subsection{Physics-based Motion Prediction}
\label{subsec:2_physics_based_mp}

Physics-based methods are the first and simplest methods used by researchers. Although the accuracy of these methods is relatively low, more and more models use the idea of physics-based models to improve the accuracy. Physics-based methods have more accurate results when the movement of vehicles can be accurately described by kinematics or dynamics models, but the physical model of the traffic participants is constantly changing, such that most of these methods are only suitable for short-term prediction (no more than 1s). Dynamics models can be quite complex, including many inherent parameters and introducing an extra computation burden, in such a way that researchers prefer simple dynamic methods for motion prediction. In terms of vehicle \ac{MP}, the bicycle model is usually employed to model the vehicle physics, driven by the front wheels \cite{kaempchen2009situation, pepy2006reducing}. In the literature three main types of physics-based models are distinguished, where the main different is the way in which the uncertainty is handled: Single Trajectory, \ac{KF}-based and Monte Carlo-based.

\subsubsection{Single-Trajectory}
\label{subsubsec:2_single_trajectory_mp}

One of the most straightforward methods to predict an agent trajectory is to directly apply the agent current state to the physic model. In order to increase the accuracy and stability of the estimation, the vehicles are mostly assumed to comply with motion models that describe their dynamic behavior. In the past, numerous single-trajectory motion models have been proposed for this task \cite{miller2002adaptive, pepy2006reducing, hillenbrand2006multilevel}. A first systematization can be achieved by defining different levels of complexity. At the lower end of such a scale, linear motion models are situated. These models assume a \ac{CV} or a \ac{CA}. Their major advantage is the linearity of the state transition equation which allows an optimal propagation of the state probability distribution. On the other hand, these models assume straight motions and are thus not able to take rotations (especially the yaw rate) into account. 

A second level of complexity can be defined by taking rotations around the $z$-axis into account. The resulting models are sometimes referred to as curvilinear models. They can be further divided by the state variables which are assumed to be constant. The most simple model of this level is the \ac{CTRV} model. By defining the derivative of the velocity as the constant variable, the \ac{CTRA} model can be derived. Both \ac{CTRV} and \ac{CTRA} assume that there is no correlation between the velocity $v$ and the yaw rate $\omega$. As a consequence, disturbed yaw rate measurements can change the yaw angle of the vehicle even if it is not moving. In order to avoid this problem, the correlation between $v$ and $\omega$ can be modeled by using the steering angle $\Phi$ (angle between the axis of motion and the direction of the front wheels) as constant variable and derive the yaw rate from $v$ and $\Phi$. The resulting model is called \ac{CSAV}. Again, the velocity can be assumed to change linearly, which leads to the \ac{CCA} model. 

From a geometrical point of view, nearly all curvilinear models are assuming that the vehicle is moving on a circular trajectory (either with a constant velocity or acceleration). The only exception is the \ac{CTRA} model, which models a linear variation of the curvature and thus assumes that the vehicle is following a clothoid. 

% While in theory curvilinear models describe the motion of road vehicles very accurately, associated errors may result from highly dynamic effects such as drifting or skidding. In this thesis, we will not consider those models which are able to cope with the effects of these errors for two reasons: Firstly, most \ac{ITS} applications are designed for scenarios with non-critical dynamics. Secondly, the required information for estimating the additional parameters (e.g. slip from every tire, lateral acceleration) are not observable by exteroceptive sensors. 

On the other hand, single trajectory methods are not able to consider the road-related factors and the uncertainty of the current state is unreliable for long-term prediction in such a way these single trajectory models should only be used for estimating uni-modal trajectories of the surrounding agents in the short-term. We further study the state transition equations of physics-based models in Chapter \ref{cha:theoretical_background} since they will be used in the algorithms proposed in this thesis as preliminary proposals for the \ac{DL} models.

\subsubsection{Kalman Filter}
\label{subsubsec:2_kalman_filter_mp}

\acf{KF}-based methods aim to solve one of drawbacks of physics-based models: In real-world, the states of agents are not perfectly known since they present an associated noise. These methods model the uncertainty of the current agent state and its physic model by means of a Normal (Gaussian) distribution. Compared to the single trajectory methods, the main advantage is that KF methods consider the uncertainty of the predicted trajectory, specially when using its Extended (EKF) or Unscented (UKF) versions where non-linearities are modeled. As proposed by the original algorithm \cite{kalman1960new}, the prediction and update steps are combined into a loop where the mean value and covariance matrix of the agent state is computed for each future step, calculated as an average trajectory with related uncertainty. 

Nevertheless, these \ac{KF}-based methods use uni-modal Gaussian distributions, which are not enough to represent agents interactions. In that sense, \cite{kaempchen2004imm} propose an Interactive Multiple Model (IMM) to compute a multi-modal prediction. Moreover, \cite{jin2015switched} model a set of \acp{KF} used to describe physical models of the vehicles and switch between them, defined as Switched Kalman Filter (SKF). \cite{lefkopoulos2020interaction} propose IMM-KF, a novel Interacting Multiple Model Kalman Filter which takes interaction-related factors (social regulation, inter-dependencies) into consideration, as shown in Figure \ref{fig:chapter_2_related_works/input_output_mp}.

\subsubsection{Monte Carlo}
\label{subsubsec:2_monte_carlo_mp}

In the same way KF methods aimed to solve the associated noise to the physics state of the agent, Monte Carlo method aims to simulate the state distribution approximately since an analytical expression for the predicted state distribution is usually unknown without any assumptions of the linearity or the model’s Gaussian nature. This method randomly samples the input variables and applies the physics model to compute potential future trajectories. In order to ensure the plausibility of the future behaviour in the context of \ac{AD}, the generated future states are usually filtered with a lateral acceleration lower than the actual allowable lateral acceleration \cite{broadhurst2005monte}, though other vehicle physical limitation can also be used such that the input of the model will be more realistic. \cite{okamoto2017driver} present a model that identifies a preliminary maneuver and then applies the Monte Carlo method to compute future trajectories by the identified maneuver. Furthermore, \cite{wang2019trajectory} first use the Monte Carlo algorithm to predict future trajectories and then utilize MPC (Model Predictive Control) algorithm to refine these preliminary future trajectories.

\begin{comment}
\subsection{Classic Machine Learning based Motion Prediction}
\label{sec:2_ml_based_mp}

Classic ML \ac{MP} methods make use of data-driven models to predict trajectories instead of only considering the physical model. These methods determine the probability distribution by mining data features. These methods provide new ideas for \ac{MP}, which promote the development of learning-based approaches. With more factors to be considered, the accuracy of these methods keeps increasing, being most of them maneuver-based (which is provided or identified in advance) in order to subsequently estimate the future states of the agents by first judging the corresponding maneuver. Regarding the field of vehicle \ac{MP}, we can find in the literature four main types of classic ML methods: Gaussian Process, Support Vector Machine (SVM), Hidden Markov Model (HMM) and Dynamic Bayesian (Network). % Figure \ref{fig:chapter_2_related_works/classic_ml_mp} illustrates some these methods. 

\begin{comment}
\begin{figure}[t!]
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{chapter_2_related_works/hmm_mp.pdf}
		\caption{Hidden Markov Model}
		\label{subfig:chapter_2_related_works/hmm_mp}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{chapter_2_related_works/dbn_mp.pdf}
		\caption{Dynamic Bayesian Network}
		\label{subfig:chapter_2_related_works/dbn_mp}
	\end{subfigure}
	
	\caption[Some typical Classic Machine Learning algorithms in Motion Prediction]{Some typical Classic Machine Learning algorithms in Motion Prediction, like Hidden Markov Model and Dynamic Bayesian Network. \\
	Source (a): \textit{Improved driving behaviors prediction based on fuzzy logic-hidden markov model} \cite{deng2018improved} \\
	Source (b): \textit{Probabilistic intention prediction and trajectory generation based on dynamic bayesian networks} \cite{he2019probabilistic}}
	
	\label{fig:chapter_2_related_works/classic_ml_mp}
\end{figure}
% \end{Comment}
	
\subsubsection{Gaussian Process}
\label{subsubsec:2_gaussian_process_mp}

Gaussian Process (GP) applied in ML \cite{rasmussen2004gaussian} is identified as an stochastic process (collection of random variables time or space indexed) such that every finite collection of those random variables has a multivariate normal distribution, i.e. every finite linear combination of them is normally distributed. This stochastic process may be used to solve the prototype trajectory method \cite{joseph2011bayesian, tran2014online}, which applies a maneuver-based method that divides agents trajectories into a collection of several types of prototype trajectories. First, past trajectories are regarded as the samples of the GP, sampled along the time axis, being these samples represented by \textit{N} discrete points to map the \textit{N}-dimensional space, which is equivalent to satisfy the \textit{N}-dimensional Gaussian distribution. Therefore, the main task of the GP model regarding the prototype trajectory method is to determine the parameters of GP through the samples. 

Once these parameters have been obtained in a stochastic way, the prototype trajectory method measures the similarity between the input historical trajectory and the computed prototype set to predict the most plausible future motion. GP can also be used to model interaction-related factors, as shown in Figure \ref{fig:chapter_2_related_works/input_output_mp}. \cite{trautman2010unfreezing} solve the frozen robot problem, where the environment surpasses a certain level of complexity and the robot planner decides to freeze in place to avoid collisions, by means of GP for joint collision avoidance. Furthermore, \cite{guo2019modeling} apply GP and Dirichlet Process (DP) to define motion processes and apply a non-parametric Bayesian network to extract potential motion patterns.

\subsubsection{Support Vector Machine (SVM)}
\label{subsubsec:2_svm_mp}

Support Vector Machine (SVM) increases the level of complexity over previous methods, being able to learn and recognize an agent maneuver in a complex environment. The main idea of SVM is to find the support vector that meets the classification requirements and determine the optimal hyperplane that can maximize the interval of the classified data. In particular, when applied to the \ac{MP} problem in \ac{AD}, driving maneuvers are usually classified into several categories: keep straight, turn left, turn right, break, etc. In that sense, it uses the kernel function to convert the input data to high-dimensional and perform linear classification in the space to identify the current driving maneuvers so as to predict the future steps. \cite{mandalia2005using} apply SVM to identify a lane changing maneuver, using the position, velocity, acceleration and steering wheel angle of the corresponding vehicle as input features for identification. \cite{kumar2013learning} propose a layered architecture method combining SVM and Bayesian filtering to identify lane-changing maneuvers so as to obtain more accurate identification results. Furthermore, \cite{aoude2009using} make use of SVM to identify the maneuvers of traffic participants. Nevertheless, according to the SVM definition which outputs the classification probability, the user must present the categories or possible maneuvers in advance, which will also impact the final prediction results.

\subsubsection{Hidden Markov Model (HMM)}
\label{subsubsec:2_hmm_mp}

As aforementioned, SVM can be effective in classification problems, but in the field of \ac{MP} for \ac{AD} not as effective as a Hidden Markov Model (HMM). This is one of the most popular maneuver-based classic ML \ac{MP} methods, which uses Markov Chain. The Markov Chain refers to a stochastic process describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event, i.e. , the state at time $t+1$ of the system is only related to the previous time $t$, and the state transition probability is not related to time. Figure \ref{subfig:chapter_2_related_works/hmm_mp} illustrates this model. The mathematical expression is:

\begin{equation}
	\begin{aligned}
		\mathrm{P}\left(S_{n+1}\right. & \left.=s \mid S_1=s_1, S_2=s_2 \cdots, S_n=s_n\right) \\
		& =\mathrm{P}\left(S_{n+1}=s \mid S_n=s_n\right)
	\end{aligned}
\end{equation}

In real life, we can only observe the distinct state that is exposed on the surface, but no intuitive representation of its hidden states exists. Therefore, it is necessary to establish a Markov process with hidden states and get the essential states of events through the observable states set related to the hidden states probability, which is the so-called Hidden Markov Model. HMM is modeled by $(S, O, A, B, \pi)$, as shown in Figure \ref{subfig:chapter_2_related_works/hmm_mp}:

\begin{itemize}
	
	\item $S=\left\{S_1, S_2, \cdots S_N\right\}$ represents the hidden states sequence
	
	\item $O=\left\{O_1, O_2, \cdots O_M\right\}$ represents the observation sequence
	
	\item $A$ represents the transition probability matrix between hidden states
	
	\item $B$ is the output matrix, representing the transition probability of hidden states to output states
	
	\item $\pi$ is the initial probability matrix, representing the initial probability distribution in hidden states
	
\end{itemize}

When HMM is used in the trajectory prediction, the historical states of traffic participants are represented by observation sequence $O$, and HMM solves the most likely future observation sequence. \cite{deng2018improved} combine HMM with Fuzzy Logic for driver maneuver prediction. In \cite{wang2021decision}, HMM is used for trajectory prediction and risk assessment, and the results are fed into the decision-making and planning system. Although traditional HMM methods have achieved a great success in predicting driver’s maneuvers, they do not consider the impact of interaction-related factors in the prediction process, such that its prediction results are not accurate enough in actual traffic scenes. To solve this issue, \cite{deo2018would} propose a vehicle trajectory prediction model based on HMM and Variational Gaussian Mixture Models (GMM) considering interaction-related factors. The vehicle interaction information is obtained by finding the optimal solution of the energy function.

\subsubsection{Dynamic Bayesian Network (DBN)}
\label{subsubsec:2_dbn_mp}

Dynamic Bayesian Networks (DBNs) \cite{koller2009probabilistic} solve the aforementioned issue of HMM when modeling the inter-dependencies among traffic participants, since in order to improve the accuracy of \ac{MP}, the prediction model should consider at least both vehicle states and the interaction effect between traffic participants. While Bayesian Networks describe static systems, DBNs introduce the concept of time segments to solve timing issues in probabilistic models. Time segment refers to a time template materialized according to DBN, which discretizes continuous time into countable points with preset time granularity. 

Generally, the preset time granularity should be consistent with the actual state acquisition frequency, and DBN is trained according to the sensor sampling frequency as the time segment. Besides, the inference and learning methods of DBN need to be converted into Bayesian Networks before they can be directly applied. The architecture of DBN includes a behavior layer, a hidden layer, and an observation layer, as shown in Figure \ref{subfig:chapter_2_related_works/dbn_mp}. The behavior layer represents the network input information, and the observation layer represents the driver’s maneuver. DBN models the effect of interaction between traffic participants when applied to trajectory prediction and perform well in classic machine learning-based methods. Using this architecture, \cite{gindele2015learning} model the driving maneuvers of multiple vehicles. The input information includes all vehicle states, vehicle interaction relationships, road structures, observation states, etc. \cite{schreier2016integrated} apply DBN to judge driving maneuvers and utilize the kinematics model corresponding to each driving maneuver to predict the trajectory. In \cite{bahram2015game}, the vehicle maneuver is predicted by game theory, and then the vehicle motion is judged by DBN that considers the interaction-related factors. In \cite{li2019dynamic}, DBN is designed to consider physics-related factors, road-related factors, and interaction-related factors. As maneuver-based methods, DBN models obtain high recognition performance and have been used in several real-world tests \cite{weidl2014optimizing}. However, DBN still faces the error problem from recognizing maneuvers to generating trajectories. Many methods can only judge two or three maneuvers, such as lane-keeping and lane-changing, and the model generalization ability is not strong.

\subsection{Reinforcement Learning based Motion Prediction}
\label{sec:2_rl_based_mp}

Reinforcement learning (RL) is one of the three basic ML paradigms, alongside supervised learning and unsupervised learning. RL is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. When RL is used in the field of \ac{MP} for \ac{AD}, most methods use the Markov decision process (MDP) to maximize the expected cumulative reward and generate optimal driving policies by learning expert demonstrations, most of which are planning-based methods. A MDP is a tuple $(\boldsymbol{S}, \boldsymbol{A}, \boldsymbol{P}, \boldsymbol{R}, \gamma)$, where $\boldsymbol{S}$ is a finite set of states, $\boldsymbol{A}$ is a finite set of actions, $\boldsymbol{P}$ is a state transition probability matrix, $P_{s s^{\prime}}^a=\mathbb{P}\left[S_{t+1}=s^{\prime}\right.$ $\left.S_t=s, A_t=a\right], \boldsymbol{R}$ is a reward function, $R_s^{\mathrm{a}}=\mathbb{E}\left[R_{t+1} \mid S_t=\right.$ $\left.s, A_t=a\right]$, and $\gamma$ is a discount factor. To find the best decision process over all policies, the optimal state-value function $v_{\star}(s)$ and the optimal action-value function $q_{\star}(s, a)$ can be calculated as:

\begin{equation}
\begin{aligned}
	v_*(s) & =\max _a\left[R_s^a+\gamma \sum_{s^{\prime} \in A} P_{s s^{\prime}}^a v_*\left(s^{\prime}\right)\right], \\
	q_*(s, a) & =R_s^a+\gamma \sum_{s^{\prime} \in A} P_{s s^{\prime}}^a \max _{a^{\prime}} q_*\left(s^{\prime}, a^{\prime}\right) .
\end{aligned}
\end{equation}

Using MDP, the RL-based methods can be classified as Inverse Reinforcement Learning (IRL) methods, Generative Adversarial Imitation Learning (GAIL) methods, and Deep IRL (DIRL) methods, which will be discussed below.

\begin{figure}[t!]
	\begin{subfigure}{0.4\textwidth}
		\includegraphics[width=\textwidth]{chapter_2_related_works/RL_mp.pdf}
		\caption{}
		\label{subfig:chapter_2_related_works/RL_mp}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{chapter_2_related_works/IRL_mp.pdf}
		\caption{}
		\label{subfig:chapter_2_related_works/IRL_mp}
	\end{subfigure}
	
	\caption[Reinforcement Learning vs Inverse Reinforcement Learning]{Reinforcement Learning (a) vs Inverse Reinforcement Learning (b) \\
	Source: \textit{A survey on trajectory-prediction methods for autonomous driving} \cite{huang2022survey}}
	\label{fig:chapter_2_related_works/RL_vs_IRL}
\end{figure}

\subsubsection{Inverse Reinforcement Learning (IRL)}
\label{subsubsec:2_irl_mp}

Usually, MDP assumes that the reward function is already provided. However, the driver’s behavior is always complicated such that manually specifying the weight of the reward function is inappropriate \cite{guan2018markov}. IRL learns the reward function according to the expert demonstration (trajectory) to generate the corresponding optimal driving policy as shown in Figure \ref{subfig:chapter_2_related_works/IRL_mp}, in contrast to the RL approach (Figure \ref{fig:chapter_2_related_works/RL_vs_IRL}) where an expert must provide the weight of a reward associated to a specific action. These IRL methods may be divided into groups: maximum margin-based and maximum entropy-based methods, where the main difference is the way of learning the weights of the reward function. 
 
Maximum margin-based methods optimize the reward function weights by minimizing the feature expectations between the expert demonstration and the predicted trajectory. For example, \cite{silver2013learning} use maximum margin planning framework to learn reward functions and learn driving maneuvers for \acp{ADS}. However, most margin-based methods are ambiguous in the matching of feature expectations, because some degeneracies can also satisfy the optimal policy of expert demonstration. 

On the other hand, Maximum entropy-based methods are more popular because they can use multiple reward functions to explain the ambiguity of experts's behavior \cite{aghasadeghi2011maximum}, most of which are based on linear mapping and can be formulated as:

\begin{equation}
\begin{aligned}
r(\Phi(s))=\theta^{\top} \Phi(s)
\end{aligned}
\end{equation}

where $r$ is the approximation of reward function; $\Phi$ is a function to output the features of the state $s$, and the weight $\theta$ will be acquired by training. Several works apply maximum entropy-based IRL (MaxEnt-IRL) to behavior prediction for AVs. In \cite{herman2015inverse}, using MaxEnt-IRL acceptability-dependent behavior models are learned from expert's trajectories to generate the stochastic behavior, then the optimum behavior model is chosen by maximizing the social acceptability. \cite{sharifzadeh2016learning} leverage IRL with Deep Q-Networks (DQN) to extract the rewards with large state spaces. In \cite{sun2018probabilistic}, interaction-related factors are considered to accomplish probabilistic prediction for \acp{ADS}. The distribution for future trajectories is formulated by driving maneuvers. Based on the decision-making mechanism, reward functions are learned using a polynomial trajectory sampler with discrete latent driving intentions in \cite{huang2021driving}.

\subsubsection{Generative Adversarial Imitation Learning (GAIL)}
\label{subsubsec:2_gail_mp}

Instead of learning the reward function from experts’ demonstration with IRL, Generative Adversarial Imitation Learning (GAIL) \cite{torabi2018generative} uses the method of GAN to do imitation learning in RL. GAIL directly extracts policies from data where, as proposed by a \ac{GAN} \cite{goodfellow2020generative}, the core idea of GAIL is that the generator generates a trajectory similar to the expert trajectory as much as possible, and the discriminator tries to judge whether it is an expert trajectory as much as possible. Many articles use GAIL to complete trajectory prediction for \ac{AD}. \cite{kuefler2017imitating} extend GAIL to the optimization of RNN to demonstrate human driver behaviors, and policies and actions are evaluated by the discriminator. In \cite{bhattacharyya2022modeling}, a parameter-sharing extension of GAIL is proposed to model the interaction between multi-agent and can provide agents with domain-specific knowledge. To overcome the shortcomings of GAIL, which only models the next state using the current state, \cite{choi2021trajgail} propose a method combining a partially observable Markov decision process (POMDP) within the GAIL framework, and the model is trained using the reward function from the discriminator.

\subsubsection{Deep Inverse Reinforcement Learning (DIRL)}
\label{subsubsec:2_dirl_mp}

Since the prediction problem in \ac{AD} is usually non-linear, i.e. the agent does not traverse in a straight path, it is necessary to use non-linear mapping for generalizable function approximations. In that sense, Deep Inverse Reinforcement Learning (DIRL) is proposed \cite{wulfmeier2015maximum} to approximate complex and nonlinear reward functions, which can be expressed as:

\begin{equation}
\begin{aligned}
r(\Phi(s))=f(\theta, \Phi(s))
\end{aligned}
\end{equation}

where $f$ is a nonlinear function. Some DIRL methods take historical trajectories as input. \cite{you2019advanced} consider the driving style and the road geometry, where the authors first use RL to design MDP, then learn the optimal driving policy from IRL, and use the deep neural network (DNN) to approximate the reward function. In \cite{fernando2020deep}, trajectories of traffic participants are encoded by LSTM and the reward network is learned by FCN. Currently, more DIRL-based methods directly use raw perception data. \cite{wulfmeier2017large} apply FCN for mapping the lidar data to traversability maps. The network is pre-trained to regress to a manual prior cost map and the initialize weights will be fine-tuned by the maximum entropy DIRL network. \cite{zhu2020off} use RL ConvNet and state visiting frequency (SVF) ConvNet to encode the vehicle’s kinematics and obtain the weight of the reward function by back-propagating the loss gradient \cite{wulfmeier2016watch} between expert SVF from expert demonstration and policy SVF from lidar data.
\end{comment}

\subsection{Deep Learning based Motion Prediction}
\label{sec:2_dl_based_mp}

\ac{DL}-based methods are by far the most used at this moment in the field of \ac{MP} in \ac{AD} to predict the future trajectory of traffic participants, being this thesis focused in these particular methods. Most traditional predictions methods \cite{huang2022survey}, which usually only consider physics-related factors (like the velocity and acceleration of the target vehicle that is going to be predicted) and road-related factors (prediction as close as possible to the road centerline), are only suitable for short-time prediction tasks \cite{huang2022survey} and simple traffic scenarios.

Recently, \ac{MP} methods based on \ac{DL} have become increasingly popular since they are able not only to take into account these above-mentioned factors but also consider interaction-related factors (like agent-agent \cite{gupta2018social}, agent-map \cite{casas2018intentnet} and map-map \cite{liang2020learning}) in such a way the algorithm can adapt to more complex traffic scenarios (intersections, sudden breaks and accelerations, etc.). It must be consider that multi-modal, specially in the field of vehicle motion prediction, does not refer necessarily to different directions (\eg \ turn to the left, turn to the right, continue forward in an intersection), but it may refer to different predictions in the same direction that model a sudden positive or negative acceleration, so as to imitate a realistic human behaviour in complex situations. % As expected, neither classical nor machine learning (ML) methods can model these situations \cite{huang2022survey}. 

\begin{figure}[h]
	\centering
	% trim={left bottom right top}
	\includegraphics[trim={0 7cm 0 7cm}, width=\linewidth]{chapter_2_related_works/DL_methods_mp.pdf}
	\caption{Deep Learning methods applied in Motion Prediction}
	Source: \textit{A survey on trajectory-prediction methods for autonomous driving} \cite{huang2022survey}
	\label{fig:chapter_2_related_works/DL_example_mp}
\end{figure}

The main \ac{DL}-based approaches are: \acp{CNN}, \acp{RNN}, \acp{GAN}, Attention mechanisms (where the Transformer architecture is included) and \acp{GNN}. Figure \ref{fig:chapter_2_related_works/DL_example_mp} illustrates the main idea of using \ac{DL} to predict the future trajectories of the agents. Since this thesis is focused on developing efficient and accurate \ac{DL}-based \ac{MP} models in the field of \ac{AD}, the theoretical explanation of the different \ac{DL} mechanisms used in our pipelines will be further detailed in Chapter \ref{cha:theoretical_background} along with some physics-based models theory to fully-understand the proposed models. The input is represented by, at least, the physics-factors of the corresponding, though road-factors and interaction-factors are present in most \ac{DL} algorithms. Then, a neural network extracts the most important features and outputs a future trajectory according to the training process in a supervised way. 

\begin{table}[h!]
	\centering
	\captionsetup{justification=justified}
	\caption[Main \textit{state-of-the-art} Deep Learning methods for Motion Prediction]{Main \ac{SOTA} \ac{DL} methods for \ac{MP}. Main categories are Encoder, Decoder, Output representation and Distribution over future trajectories}
	\begin{adjustbox}{max width=\textwidth}
		\begin{tabular}{l |ccc|c|c|c}
			\toprule
			%\hline
			\textbf{Method}	&	& \textbf{Encoder}	&	& \textbf{Decoder}	& \textbf{Output}  & \textbf{Trajectory Distribution}	\\
			& Motion history	& Social info	& Map info	&	&	&	\\
			\midrule
			% \midrule
			% \hline
			SocialLSTM \cite{alahi2016social}	& LSTM	& spatial pooling	& --	& LSTM	& states	& samples	\\
			SocialGan \cite{gupta2018social}	& LSTM	& maxpool	& --	& LSTM	& states	& samples	\\
			Jean \cite{mercat2020multi}	& LSTM	& attention	& --	& LSTM	& states	& GMM	\\
			TNT \cite{zhao2021tnt}	& polyline	& maxpool, attention	& polyline	& MLP	& states	& weighted set	\\
			LaneGCN \cite{liang2020learning}	& 1D-conv	& GNN	& GNN	& MLP	& states	& weighted set	\\
			WIMP \cite{khandelwal2020if}	& LSTM	& GNN+attention	& polyline	& LSTM	& states	& GMM	\\
			VectorNet \cite{gao2020vectornet}	& polyline	& maxpool, attention	& polyline	& MLP	& states	& uni-modal	\\
			SceneTransformer \cite{ngiam2022scene}	& attention	& attention	& polyline	& attention	& states	& weighted set	\\
			HOME \cite{gilles2021home}	& raster	& attention	& raster	& conv	& states	& heatmap	\\
			GOHOME \cite{gilles2022gohome}	& 1D-conv+GRU	& GNN	& GNN	& MLP	& states	& heatmap	\\
			MP3 \cite{casas2021mp3}	& raster	& conv	& raster	& conv	& cost function	& weighted samples	\\
			CoverNet \cite{phan2020covernet}	& raster	& conv	& raster	& lookup	& states	& GMM w/ dyn. anch.	\\
			DESIRE~\cite{lee2017desire}	& GRU	& spatial pooling	& raster	& GRU	& states	& samples	\\
			MFP \cite{tang2019multiple}	& GRU	& RNNs+attention	& raster	& GRU	& states	& samples	\\
			MANTRA \cite{marchetti2020mantra}	& GRU	& --	& raster	& GRU	& states	& samples	\\
			PRANK \cite{biktairov2020prank}	& raster	& conv	& raster	& lookup	& states	& weighted set	\\
			IntentNet \cite{casas2018intentnet}	& raster	& conv	& raster	& conv	& states	& uni-modal	\\
			Multi-modal \cite{cui2019multimodal}	& raster	& conv	& raster	& conv	& states	& weighted set	\\
			MultiPath \cite{chai2019multipath}	& raster	& conv	& raster	& MLP	& states	& GMM w/ static anchors	\\
			MultiPath++ \cite{varadarajan2022multipath++}	& LSTM	& RNNs+maxpool	& polyline	& MLP	& control poly	& GMM	\\
			PLOP \cite{buhet2021plop}	& LSTM	& conv	& raster	& MLP	& state poly	& GMM	\\
			Trajectron++ \cite{salzmann2020trajectron++}	& LSTM	& RNNs+attention	& raster	& GRU	& controls	& GMM	\\
			CRAT-PRED \cite{schmidt2022crat}	& LSTM	& GNN+attention	& --	& MLP	& states	& weighted set	\\
			R2P2 \cite{rhinehart2018r2p2}	& GRU	& --	& polyline	& GRU	& motion	& samples	\\
			DKM \cite{cui2020deep}	& raster	& conv	& raster	& conv	& controls	& weighted set	\\
			GANet \cite{wang2022ganet}	& 1D-conv+GRU	& GNN	& GNN	& MLP	& states	& weighted set	\\
			\bottomrule
			% \hline
		\end{tabular}
		\label{table:2_dl_related_work_mp}
	\end{adjustbox}
\end{table}

In order to classify \ac{DL} based \ac{MP} methods, we can identify different factors (physics, interaction and road) and determine which type of neural network is employed to extract features of the corresponding input. In the literature we mainly distinguish the following inputs and outputs: Motion history (physics-based factors), Social information (interaction-based factors), Map information (road-relared factors), how the model returns the output trajectory and its corresponding distribution. Table \ref{table:2_dl_related_work_mp} summarizes main \ac{SOTA} methods.

\begin{itemize}
	
	\item \textbf{Motion history}: Most methods encode the sequence of past observed states using 1D-\ac{CNN} \cite{liang2020learning, mercat2020multi}, able to model spatial information, or via a recurrent net \cite{alahi2016social} (\ac{LSTM}, \ac{GRU}), which are more useful to handle temporal information. Other methods that use a raster version of the whole scenario represent the agent states rendered as a stack of binary mask images depicting agent oriented bounding boxes \cite{gilles2021home}. On the other hand, other approaches encode the past history of the agents in a similar way to the road components of the scene given a set of vectors or polylines \cite{zhao2021tnt, gao2020vectornet} that can model the high-order interactions among all components, or even employing attention to combine features across road elements and agent interactions \cite{ngiam2022scene}. In our approaches, we will mainly use \ac{LSTM}, 1D-\ac{CNN} and Attention mechanism given the relative displacements of the agents.
	
	\item \textbf{Social information}: In complex scenarios, motion history encoding of a particular target agent is not sufficient to represent the latent space of the traffic situation, but the algorithm must deal with a dynamic set of neighbouring agents around the target agent. Common techniques are aggregating neighbour motion history with a permutation-invariant set operator: soft attention \cite{ngiam2022scene}, a combination of soft attention and \ac{RNN} \cite{varadarajan2022multipath++} / \ac{GNN} \cite{schmidt2022crat} or social pooling \cite{alahi2016social, gupta2018social}. Raster based approaches rely on 2D convolutions \cite{chai2019multipath} \cite{casas2021mp3} over the spatial grid to implicitly capture agent interactions in such a way long-term interactions are dependent on the neural network receptive fields. We will make use of Attention-based and \ac{GNN}-based algorithms in our approaches.
	
	\item \textbf{Map information}: High-fidelity maps \cite{can2022maps} have been widely adopted to provide offline information (also known as physical context) to complement the online information provided by the sensor suite of the vehicle and its corresponding algorithms. Recent learning-based approaches \cite{mahjourian2022occupancy, casas2018intentnet, ivanovic2021heterogeneous}, which present the benefit of having probabilistic interpretations of different behaviour hypotheses, require to build a representation to encode the trajectory and map information. Map information is probably the feature with the clearest dichotomy: raster vs vector treatment. The raster approach encodes the world around the particular target agent as a stack of images (generally from a top-down orthographic view, also known as Bird's Eye View). This world encoding may include from agent state history, agent interactions and usually the road configuration, integrated all this different-sources information as a multi-channel image \cite{gilles2021home}, in such a way the user can use an off-the-shelf \ac{CNN}-based pipeline in order to leverage this powerful information. Nevertheless, this representation has several downsides: constrained field of view, difficulty in modeling long-range interactions and even difficulty in representing continuous physical states due to the inherent world to image (pixel) discretization. 
	
	On the other hand, the polyline approach may describe curves, such as lanes, boundaries, intersections and crosswalks, as piecewise linear segments, which usually represents a more compact and efficient representation than using CNNs due to the sparse nature of road networks. Some state-of-the-art algorithms not only describe the world around a particular agent as a set-of-polylines \cite{khandelwal2020if} \cite{zhao2021tnt} in an agent-centric coordinate system, but they also leverage the road network connectivity structure \cite{liang2020learning} \cite{zeng2021lanercnn} treating road lanes as a set of nodes (waypoints) and edges (connections between waypoints) in a graph neural network so as to include the topological and semantic information of the map. In our case, we will use discrete map information in the form of target goals and high-level well-structured centerlines, as well as road network connectivity structure using \ac{GNN}-based operations to compute deep physical features.
	
	\item \textbf{Decoder}: Pioneering works of DL based MP usually adopt the autoencoder architecture, where the decoder is often represented by a recurrent network (\ac{GRU}, \ac{LSTM}, etc., specially designed to handle temporal information) to generate future trajectories in an autoregressive way, or by CNNs \cite{gilles2021home} \cite{gilles2022gohome} / MLP \cite{liang2020learning} \cite{schmidt2022crat} using the non-autoregressive strategy. The method may use an autoregressive strategy where the pipeline generates tokens (in this case, positions or relative displacements) in a sequential manner, in such a way the new output is dependent on the previously generated output, whilst \ac{MLP} \cite{schmidt2022crat}, \ac{CNN} \cite{gilles2021home} or transformer \cite{ngiam2022scene} based strategies usually follow a non-auto-regressive approach, where from a latent space the whole future trajectory is predicted. Throughout this work, we will make use of the auto-regressive strategy using \ac{LSTM} networks as well as the decoding from the latent space in the latest proposed algorithm, where we will appreciate that given an enriched encoded representation, it is possible to directly decode from the deep features instead of carrying out the decoding process iteratively.
	
	\item \textbf{Output}: The most popular model output representation is a sequence of states (absolute positions) or state differences (relative displacements for any dimension considered). The spacetime trajectory may be intrinsically represented as a continous polynomial representation or a sequence of sample points. Other works \cite{gilles2021home} \cite{gilles2022gohome} first predict a heatmap and then decode the corresponding output trajectories after sampling points from the heatmap, whilst \cite{casas2021mp3} \cite{zeng2019end} learn a cost function evaluator of trajectories that are enumerated heuristically instead of being generated by a learned model. As proposed by most methods, we will represent our output as a sequence of states, being absolute positions when decoding from the encoded latent space or relative displacements when decoding iteratively by means of the auto-regressive approach as aforementioned.
	
	\item \textbf{Trajectory Distribution}: The choice of output trajectory distributions has several approaches on downstream applications. Regardless the agent to be predicted is described as a (non-)holonomic \cite{triggs1993motion} platform, an intrinsic property of the \ac{MP} problem is that the agent may follow one of a diverse set of possible future trajectories, instead of a single future trajectory (uni-modal) \cite{gao2020vectornet}, which might not be optimal. To address the multi-modal issue, a popular choice to represent a multi-modal prediction are Gaussian Mixture Models (GMMs) due to their compact parameterized form, where mode collapse (associated frequently to GMMs) is addressed through the use of trajectory anchors \cite{chai2019multipath} or training  tricks \cite{cui2019multimodal}. Other approaches model a discrete distribution via a collection of trajectory samples extracted from a latent space and decoded by the model \cite{rhinehart2018r2p2} or over a set of trajectories (fixed a priori or learned). In that sense, at the moment of writing this work, the most used trajectory distribution is a weighted set of trajectories \cite{liang2020learning, zhao2021tnt, schmidt2022crat}, where each set is a trajectory with a discrete number of future steps and an associated confidence indicating the probability of occurrence of the corresponding behaviour. In this work, for those approaches which make use of the multi-modal approach, a weighted set will be used to model the trajectory distribution, where each trajectory is a sequence of discrete states, and each sequence has a certain confidence illustrating the probability of occurrence of that particular behaviour.
	
\end{itemize}

\section{Motion Prediction Datasets}
\label{sec:2_motion_prediction_datasets}

As stated in previous sections, \ac{MP} (also referred in the literature as Motion Forecasting) addresses the problem of predicting future states (or occupancy maps) for dynamic actors within a local environment. Some examples of relevant actors for autonomous driving include: vehicles (both parked and moving), pedestrians, cyclists, scooters, and pets. Predicted futures generated by a forecasting system are consumed as the primary inputs in motion planning, which conditions trajectory selection on such forecasts. Generating these forecasts presents a complex, multi-modal problem involving many diverse, partially-observed, and socially interacting agents. Considering these requirements, there are several datasets in the literature to train and validate multiple proposals that vary in terms of data size, geographic coverage, sensor modalities, annotations, and limitations. Choosing the most appropriate dataset depends on the specific research goals, target environment, and available resources. Researchers should consider these factors when selecting a dataset for motion forecasting tasks in autonomous driving. Table \ref{table:2_motion_prediction_datasets_comparison} shows an interesting comparison between different \ac{SOTA} datasets in the field of vehicle \ac{MP}.

\begin{table}[!tpbh]
	\centering
	\captionsetup{justification=justified}
	\caption[Comparison between different \textit{state-of-the-art} vehicle Motion Prediction datasets]{Comparison between different \textit{state-of-the-art} vehicle Motion Prediction datasets. Hyphens "-" indicate that attributes are either not applicable, or not available. $\dagger$ Public leaderboard counts as retrieved on Aug. 27, 2021. \\
	Source: \textit{Argoverse 2: Next generation datasets for self-driving perception and forecasting} \cite{wilson2023argoverse}}
	\label{table:2_motion_prediction_datasets_comparison}
	\begin{adjustbox}{max width=\columnwidth}
		\begingroup
		\renewcommand{\arraystretch}{1.25} %
		\begin{tabular}{rccccccc}
			\toprule
			& \textsc{Argoverse 1}~\cite{chang2019argoverse} & \textsc{Interaction}~\cite{zhan2019interaction} & \textsc{Lyft}~\cite{john2020one} & \textsc{Waymo}~\cite{ettinger2021large} & \textsc{NuScenes}~\cite{caesar2020nuscenes} & \textsc{Yandex}~\cite{malinin2021shifts} & \textsc{Argoverse 2}~\cite{wilson2023argoverse} \\
			\midrule
			\textsc{Scenarios} & 324k & - & 170k & 104k & 41k & 600k & 250k \\
			\textsc{Unique Tracks} & 11.7M  & 40k & 53.4M & 7.6M & - & 17.4M & 13.9M  \\
			\textsc{Average Track Length} & 2.48 s & 19.8 s & 1.8 s & 7.04 s & - & - & 5.16 s  \\
			\textsc{Total Time} & 320 h & 16.5 h & 1118 h & 574 h & 5.5 h & 1667 h & 763 h \\
			\textsc{Scenario Duration} & 5 s & - & 25 s & 9.1 s & 8 s & 10 s & 11 s \\
			\textsc{Test Forecast Horizon} & 3 s & 3 s & 5 s & 8 s & 6 s & 5 s & 6 s \\
			\textsc{Sampling Rate} & 10 Hz & 10 Hz & 10 Hz & 10 Hz & 2 Hz & 5 Hz & 10 Hz \\
			\textsc{Cities} & 2 & 6 & 1 & 6 & 2 & 6 & 6  \\
			\textsc{Unique Roadways} & 290 km & 2 km & 10 km & 1750 km & - & - & 2220 km \\
			\textsc{Avg. tracks per scenario} & 50 & - & 79 & - & 75 & 29 & 73\\
			\textsc{Evaluated object categories} & 1 & 1 & 3 & 3 & 1 & 2 & 5 \\
			\textsc{Multi-agent evaluation} & $\times$ & \checkmark & \checkmark & \checkmark & $\times$ & \checkmark &\checkmark \\
			\textsc{Mined for Interestingness} & \checkmark & $\times$ & - & \checkmark & $\times$ & $\times$ & \checkmark \\
			\textsc{Vector Map} & \checkmark & $\times$ & $\times$ & \checkmark & \checkmark & $\times$ &\checkmark \\
			\textsc{Download Size} & 4.8 GB  & -  & 22 GB  & 1.4 TB  & 48 GB & 120 GB & 58 GB \\
			\textsc{Public Leaderboard Entries}$^\dagger$ & 194  & -  & 935  & 23 & 18 & 3 & - \\
			\bottomrule
		\end{tabular}
		\endgroup
	\end{adjustbox}
\end{table}

As observed, Yandex is the dataset with the highest number of scenarios, total recorded time and amount of data, but there are very few entries and all of them dated from 2021, so, at the moment of writing this thesis, the research community is not focused in this dataset anymore. On the other hand, Lyft has the highest number of entries, but the number of unique roadways is limited to 10 km and it does not provide a vector map. Interaction is limited to some interesting scenarios, with very few unique tracks and roadways compared to the other datasets. Overall, these datasets have common goals of enabling motion prediction and improving the safety and efficiency of \acp{ADS}. However, their coverage, data size, features, and limitations vary, which makes it important to consider the specific requirements and use cases when choosing a dataset for research or development purposes. 

Regarding this, we conclude the best vehicle \ac{MP} datasets in the literature are NuScenes, Waymo, Argoverse 1 and Argoverse 2. In that sense, since the \ac{DL} part of the thesis was started (around 2021) approximately when Argoverse 1 had a lot of interest from the research community, and, on top of that, they recently released Argoverse 2 ()the largest \ac{MP} dataset to date) we finally decided to build our algorithms upon the Argoverse 1 and Argoverse 2 datasets.

\subsection{Argoverse 1 Motion Forecasting}
\label{subsec:2_argoverse_1}

The Argoverse 1 Motion Forecasting dataset is a widely used dataset in the field of \ac{AD} for studying and developing algorithms related to \ac{MP}. It includes HD maps and a detailed map API to get the corresponding rasterized or vector information of the map. This dataset is a curated collection of 324,557 scenarios (particularly, 205942 training samples, 39472 validation samples and 78143 test samples). Data was sampled at 10 Hz, where each sample contains the \ac{BEV} position (x,y) of all agents in the scene in the past 2s (20 observed points), the local map, and the labels are the 3s (30 predicted points) future positions of one target agent in the scene. For training and validation, full 5-second trajectories are provided, while for testing, only the first 2 seconds trajectories are given. 

\begin{table}[!tpbh]
	\centering
	%\captionsetup{justification=justified}
	\caption[Distribution of the Target Agent Maneuver in the Argoverse 1 Motion Forecasting Dataset]{Distribution of the Target Agent Maneuver in the Argoverse 1 Motion Forecasting Dataset \\
	Source: \textit{Improving diversity of multiple trajectory prediction based on map-adaptive lane loss} \cite{kim2022improving}}
	\label{table:2_argoverse1_maneuvers_distribution}
	\begin{tabular}{c|c|c}
		\toprule
		Maneuver & Training  & Validation\\
		\midrule
		Going straight & 191024 (92.75\%) & 34958 (90.70\%) \\
		Left turn & 7860 (3.82\%) & 1880 (4.88\%) \\
		Right turn & 4757 (2.31\%) & 1238 (3.21\%) \\
		Left lane change & 1084 (0.53\%) & 284 (0.74\%) \\
		Right lane change & 1217 (0.59\%) & 184 (0.48\%) \\
		\bottomrule
	\end{tabular}
\end{table} 

Table \ref{table:2_argoverse1_maneuvers_distribution} shows an estimated distribution of the target agent maneuver in the Argoverse 1 dataset, regarding the most common use cases in urban scenarios, such as going straight, turn and lane change. We can observe how most sequences are focused on keeping the same lane. Nevertheless, most of these \textit{going straight} use cases do not conduct a trivial constant velocity trajectory, but there are sudden accelerations or breaks, which are quite interesting and challenging.

We have used this dataset to train and validate our algorithms in Chapters \ref{cha:exploring_gan_for_vehicle_mp}, \ref{cha:efficient_baseline_for_mp_in_ad}.

\subsection{Argoverse 2 Motion Forecasting}
\label{subsec:2_argoverse_2}

We have used the Argoverse 2 \cite{wilson2023argoverse} Motion Forecasting dataset to implement and validate our final \ac{MP} included in Chapter \ref{cha:improving_multi_agent}. In the same way than Argoverse 1, Argoverse 2 is a high-quality \ac{MP} dataset where the real driving scenario are paired with the corresponding local HD map. Nevertheless, while Argoverse 1 provides a substantial amount of labeled data, it may still have limitations in capturing the full diversity of real-world driving scenarios. Built upon the success of Argoverse 1, the Argoverse 2 Motion Forecasting dataset provides an updated set of prediction scenarios collected from a self-driving fleet, improving its previous version by spanning +2000 km over six different cities and the traffic scenarios approximately twice longer and more diverse.

\begin{comment}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\columnwidth]{chapter_2_related_works/mp_mf_score_plateau.pdf}
	\caption[MinFDE metric values for submissions on Argoverse 1 over time]{MinFDE metric values for submissions on Argoverse 1 over time. Individual points indicate submissions to the public leader board. Colors indicate specific competition phases. The solid black line indicates SOTA performance}
	\label{fig:chapter_2_related_works/mp_mf_score_plateau}
\end{figure}
\end{comment}
	
The design decisions \cite{wilson2023argoverse} to create the Argoverse 2 dataset as a noticeable enhanced version of Argoverse 1 were:

\begin{itemize}
	
	\item \textbf{Motion forecasting is a safety critical system in a long-tailed domain}: A good dataset must be biased towards diverse, interesting and challenging scenarios containing different types of focal agents. The Argoverse 2 goal is to encourage the development of methods that ensure safety during tail events, rather than to optimize the expected performance on easy miles where even simple models are able to solve the problem.
	
	\item \textbf{Goldilocks zone of task difficulty}: The number and diversity of methods performing at or near the \ac{SOTA} continues growing since early 2020 when Argoverse 1 was released, but the performance on the test set (leaderboard) has begun to plateau, also referred in the literature as goldilocks zone.

	In that sense, Argoverse 2 is designed to increase prediction difficulty incrementally, spurring productive focused research for the next few years. These changes are intended to encourage methods that perform well on extended forecast horizons (3 s $\rightarrow$ 6 s), handle multiple types of dynamic objects (1 $\rightarrow$ 5), and ensure safety in scenarios from the long tail. Future Argoverse releases could continue to increase the problem difficulty by reducing observation windows and increasing forecasting horizons.
	
	\item \textbf{Usability matters}: Argoverse 1 benefited from a large and active research community in large part due to the simplicity of setup and usage. Existing Argoverse models can be easily ported to run on Argoverse 2. In particular, the Argoverse 2 have prioritized intuitive access to map elements,  encouraging methods which use the lane graph as a strong prior. To improve training and generalization, all poses have also been interpolated and resampled at exactly \SI{10}{\hertz} (Argoverse 1 was approximate). In that sense, Argoverse 2 includes fewer, but longer and more complex scenarios. This ensures that total dataset size remains large enough to train complex models but small enough to be easily downloadable and manageable.
	
\end{itemize}

\subsection{Evaluation metrics}
\label{subsec:2_evaluation_metrics}

Most \ac{MP} datasets (either in the field of \ac{AD} or others focused on pedestrian motion prediction) use the same metrics to evaluate the performance of the different proposed algorithms. In this work we focus on the most important ones: \ac{minADE} and \ac{minFDE} (both in the uni-modal and multi-modal scenario) to evaluate our models with respect to the \ac{SOTA} both in terms of validation and tests sets.

\begin{enumerate}
	
	\item The minimum Average Displacement Error (minADE, also referred as $ADE_{K=N}$) measures the average $\mathcal{L}_2$ distance between the best predicted trajectory and the ground-truth trajectory over all time steps. The best here refers to the trajectory (or mode) that has the minimum average error. It is defined as:
	
	\[
	minADE = \min_{i=1}^{K=N} \left( \frac{1}{T}\sum_{t=1}^{T}\sqrt{{(x_{i,t}^{pred} - x_{i,t}^{gt})}^2 + {(y_{i,t}^{pred} - y_{i,t}^{gt})}^2} \right)
	\]
	
	where $K=N$ is the total number of predictions or modes, $T$ is the number of time steps, $(x_{i,t}^{pred}, y_{i,t}^{pred})$ are the predicted coordinates of vehicle $i$ at time step $t$, and $(x_{i,t}^{gt}, y_{i,t}^{gt})$ are the ground-truth coordinates of vehicle $i$ at time step $t$. The \ac{minADE} metric penalizes the algorithm for the worst average displacement error among all the predictions.
	
	\item The minimum Final Displacement Error (minFDE, also referred as $FDE_{K=N}$) measures the minimum $\mathcal{L}_2$ distance between the final predicted position and the corresponding ground-truth position. The best here refers to the trajectory (or mode) that has the minimum average error. It is defined as:
	
	\[
	minFDE = \min_{i=1}^{K=N} \sqrt{{(x_{i,T}^{pred} - x_{i,T}^{gt})}^2 + {(y_{i,T}^{pred} - y_{i,T}^{gt})}^2}
	\]
	
	where $(x_{i,T}^{pred}, y_{i,T}^{pred})$ are the predicted coordinates of vehicle $i$ at the last time step $T$, and $(x_{i,T}^{gt}, y_{i,T}^{gt})$ are the ground truth coordinates of vehicle $i$ at the last time step $T$. The \ac{minFDE} metric penalizes the algorithm for the worst final displacement error among all the predictions.
	
\end{enumerate}

In this work, except for the GAN-based model (Chapter \ref{cha:exploring_gan_for_vehicle_mp}) which is focused on uni-modal prediction, we report results for $K=1$ (uni-modal case, only the mode with the best confidence is considered) and $K=6$ as this is the standard multi-modal in the Argoverse 1 and 2 Motion Forecasting datasets in order to compare with other models.

\section{Comparison of \textit{state-of-the-art} simulators in Autonomous Driving}
\label{sec:2_sota_simulators_ad}

The last section of this Chapter focuses on justifying the necessity of why a hyper-realistic simulator is required to validate the algorithms instead of only using the graphics and metrics calculated on the corresponding datasets. We aim to integrate the best proposal of the thesis with other upstream and downstream modules developed in our research group (specially the \ac{MOT} and \ac{DM} modules) to validate the influence of the prediction step in a holistic way.

%, a brief comparison with the \ac{SOTA} and the simulator we will use in the experimental results to validate the corresponding algorithms. 

% A fully-autonomous driving architecture (L5 in the J3016 SA  \cite{taxonomy2016definitions}) is still years away, mainly due to technical challenges, but also due to social and legal ones \cite{matthaeia2015autonomous}. The Society of Automotive Engineers (SAE) stated a taxonomy with five levels \cite{taxonomy2016definitions} of driving automation, in which the level zero stands for no automation and level five for full-automation. Level one (L1) includes primitive ADAS (Advanced Driver Assistance Systems) such as Adaptive Cruise Control, stability control or anti-lock braking systems \cite{rajamani2011vehicle}. Once the system has longitudinal and lateral control in a specific use case (although the driver has to monitor the system at all times), level two (L2) becomes a feasible technology. Then, the real challenge arises above this level. Level three (L3) is conditional automation, that is, the system has longitudinal and lateral control in specific use cases, so the driver does not have to monitor the system at all times. However, the system recognizes the performance limits and the driver is requested to resume control (s/he must be in position) within a sufficient time margin. In that sense, the takeover maneuver (transition from automatic to manual mode) is an issue yet to be solved. Since recent studies \cite{gold2016taking} \cite{merat2014transition} have demonstrated how it increases the likelihood of an accident during the route, in particular if the driver is not aware of the navigation. 

% Besides this, we find levels four and five, in which human attention is not required anymore in specific use cases (L4) or any weather condition and road conditions (L5), which represent an open and challenging problem. The environment variables, from surrounding behaviour to weather conditions, are highly stochastic and difficult to model. In that sense, no industry organization has shown a ratified testing methodology for L4/L5 autonomous vehicles. The \ac{AD} community gives a simple reason: despite the fact that some regulations have been defined for these levels and current automotive companies/research groups are very good at testing the individual components of the AD architecture using the corresponding datasets \cite{geiger2012we} \cite{caesar2020nuscenes, zhan2019interaction}, there is a need to test intelligent vehicles full of advanced sensors \cite{schoner2017role} in an end-to-end way. In this context, artificial intelligence is increasingly being involved in processes such as detecting the most relevant objects around the car (DL based multi-object tracking systems), or evaluating the current situation of the vehicle to conduct the safest decision (\eg \ Deep Reinforcement Learning applied to behavioural systems). Moreover, it is important to consider the presence of sensor redundancy in order to establish a safe navigation in such a way the different sensors and associated algorithms are integrated together, to validate the whole system and not just individual components.

In order to validate a whole \ac{ADS} the system must be tested in countless environments and scenarios, which would escalate the cost and development time exponentially with the physical approach. Considering this, the use of photo-realistic simulation (virtual development and validation testing) and an appropriate design of the driving scenarios are the current keys to build safe and robust \ac{AD} technology. These simulators have evolved from merely simulating vehicle dynamics to also simulating more complex functionalities. Simulators intended to be used for testing \ac{AD} technology must have requirements that extend from simulating physical car models to several sensor models, path planning, control and so forth and so on. Some \ac{SOTA} simulators \cite{kaur2021survey} are as following:

\begin{itemize}
	
	% \item \textbf{MATLAB/Simulink \cite{lattarulo2017complete}} published its Automated Driving Toolbox, that provides several tools which facilitate the design, simulation and testing of automated driving systems and Advanced Driver Assistance Systems (ADAS). One of its key features is that OpenDRIVE \cite{dupuis2010opendrive} road networks can be imported into MATLAB and may be used for varios testing and design purposes. This Automated Driving toolbox also supports Hardware-in-the-Loop (HIL) testing as well as C/C++ generation, which enables faster prototyping.
	
	\item \textbf{CarSim} \cite{benekohal1988carsim} is a vehicle simulator commonly used by academia and industry. Its newest version supports moving objects and sensors that benefit simulations involving self-driving tecnology and ADAS. These moving objects may be linked to 3D objects with their own embedded animations, such as vehicles, cyclists or pedestrians.
	
	\item \textbf{PreScan} \cite{tideman2013simulation} provides a simulator framework to design self-driving cars and \ac{ADAS}. It presents PreScan's automatic traffic generator which enables manufacturers to validate their autonomous navigation architectures providing a variety of realistic environments and traffic conditions. This simulator also supports HIL simulation, quite common for evaluating Electronic Control Units (ECUs) used in real-world applications.
	
	\item \textbf{\ac{CARLA}} \cite{dosovitskiy2017carla} an open-source autonomous driving simulator implemented as a layer over Unreal Engine 4 (UE4) \cite{sanders2016introduction}. This simulation engine provides to \ac{CARLA} an ecosystem of interoperable plugins, a realistic physics and a state-of-the-art image quality. \ac{CARLA} is designed as a server-client system so as to support this functionality provided by UE4, where the simulation is rendered and run by the server. The environment is composed of 3D models of static objects, such as buildings, infrastructure or vegetation, as well as dynamic objects like pedestrians, cyclists or vehicles. These objects are designed using low-weight geometric textures and models though maintaining visual realism by making use of variable level of detail and carefully crafting the materials. Moreover, one of the main advantages when using \ac{CARLA} is the possibility to modify in an easy way the vehicle on-board sensors and their features in order to obtain accurate data, the weather and even the possibility to create realistic traffic scenarios.
	
	\item \textbf{Gazebo} \cite{koenig2004design} is an scalable, open-source, flexible and multi-robot 3D simulator. It supports the recreation of both outdoor and indoor environments in which there are two core elements that define the 3D scene, also known as world and model. The world is used to represent the 3D scene, defined in a Simulation Description File (SDF) and a model is basically any 3D object. Gazebo uses Open Dynamic Engine (ODE) as its default physic engine.
	
	\item \textbf{LGSVL (LG Electronics America R\&D Center)} \cite{rong2020lgsvl} is the most recent simulator for testing autonomous driving technology, focused on multi-robot simulation. It is based on the Unity game engine \cite{haas2014history}, providing different bridges for message passing between the simulator backbone and the autonomous driving stack. LGSVL provides a PythonAPI to control different environment entitities, such as weather conditions, the position of the adversaries, etc. in a similar way to the \ac{CARLA} simulator. It also provides Functional Mockup Interface (FMI) so as to integrate vehicle dynamics platform to the external third party dynamics models.
	
\end{itemize}

In order to choose the right simulator, there is a set of criteria \cite{kaur2021survey} that may serve as a metric to identify which simulators are most suitable for our purposes. In our case we have selected such as perception (sensors and weather conditions), multi-view geometry, traffic infrastructure, vehicle control, traffic scenario simulation, 3D virtual environment, 2D/3D groundtruth, scalability via a server multi-client architecture and last but not the least, if the simulator is open-source. In Table \ref{table:2_simulators_ad_comparison}, we provide a comparison summary where all five simulators aforementioned are further compared. For further details about this \ac{AD} comparison, we refer the reader to \cite{kaur2021survey}.

\begin{comment}
\begin{table}[h]
	\caption[Comparison of some \textit{state-of-the-art} simulators for \ac{AD}]{Comparison of some \textit{state-of-the-art} simulators for \ac{AD}. GT stands for Ground-Truth. Y=supported, N=Not Support, U=Unknown, TL=Traffic Light, SS=Stop Signal, Int=Intersections, In=Indoor, Out=Outdoor}
	\label{table:2_simulators_ad_comparison}
	\centering
	%\begin{adjustbox}{max width=\columnwidth}
	% \resizebox{\linewidth}{!}{
			\begin{tabular}{p{0.15\linewidth}||p{0.1\linewidth}|p{0.1\linewidth}|p{0.1\linewidth}|p{0.1\linewidth}|p{0.1\linewidth}|p{0.1\linewidth}}
			% \begin{tabular}{c || c | c | c | c | c | c}
				\toprule
				\textbf{Requirements} & \textbf{MATLAB} & \textbf{CarSim} & \textbf{PreScan} & \textbf{CARLA} & \textbf{Gazebo} & \textbf{LGSVL}\\
				\midrule
				\textbf{Perception}: Sensor models supported & Y & Y  & Y & Y & Y & Y \\
				\midrule
				\textbf{Perception}: Different weather conditions & N & N  & Y  & Y & N & Y \\
				\midrule
				\textbf{Camera Calibration} & Y & N  & Y & Y & N  & N \\
				\midrule
				\textbf{Path Planning} & Y & Y  & Y  & Y & Y & Y \\
				\midrule
				\textbf{Vehicle Control}: Proper vehicle dynamics & Y & Y  & Y  & Y & Y & Y \\
				\midrule
				\textbf{3D Virtual Environment} & U & Y  & Y  & Y, Out (Urban) & Y, In \& Out & Y, Out (Urban) \\
				\midrule
				\textbf{Traffic Infrastructure} & Y, allows to build lights model & Y  & Y & Y, TLs, Ints, SSs, lanes  & Y, allows to manually build all kinds of models & Y \\
				\midrule
				\textbf{Traffic Scenario simulation}: Different types of Dynamic objects & Y & Y & Y & Y & N & Y \\
				\midrule
				\textbf{2D/3D GT} & Y & N & N & Y & U & Y \\
				\midrule
				\textbf{Interfaces to other software} & Y,  with Carsim, Prescan,ROS & Y, with Matlab & Y, with MATLAB & Y, with ROS, Autoware & Y, with ROS & Y, with Autoware, Apollo, ROS \\
				\midrule
				\textbf{Scalability} via a server multi-client architecture & U & U & U & Y & Y & Y \\
				\midrule
				\textbf{Open Source} & N & N & N & Y & Y & Y \\
				\midrule
				\textbf{Stability} & Y & Y & Y & Y & Y & Y \\
				\midrule
				\textbf{Portability} & Y & Y & Y & Y, Windows \& Linux & Y, Windows \& Linux & Y, Windows \& Linux \\
				\midrule
				\textbf{Flexible API} & Y & Y & U & Y & Y & Y \\
				% \hline
				\bottomrule
			\end{tabular}%}
	%\end{adjustbox}
\end{table}
\end{comment}

\begin{table}[h]
	\centering
	\captionsetup{justification=justified}
	\caption[Comparison of some \textit{state-of-the-art} simulators for Autonomous Driving]{Comparison of some \textit{state-of-the-art} simulators for \ac{AD}. GT stands for Ground-Truth. \cmark \ and \xmark \ indicate that the corresponding requirement is supported or not respectively. U = Unknown, TL = Traffic Light, SS = Stop Signal, INT = Intersections, IN = Indoor, OUT = Outdoor, ROS = Robot Operating System. MCA = Multi-Client Architecture. Hyphens "-" indicate that attributes are either not applicable, or not available.}
	\label{table:2_simulators_ad_comparison}
	%\begin{adjustbox}{max width=\columnwidth}
	\resizebox{\linewidth}{!}{
		%\begin{tabular}{p{0.15\linewidth}||p{0.1\linewidth}|p{0.1\linewidth}|p{0.1\linewidth}|p{0.1\linewidth}|p{0.1\linewidth}|p{0.1\linewidth}}
	    \begin{tabular}{c || c | c | c | c | c}
				\toprule
				\textbf{Requirements} & \textbf{CarSim} & \textbf{PreScan} & \textbf{\ac{CARLA}} & \textbf{Gazebo} & \textbf{LGSVL} \\
				\midrule
				\textbf{Sensor models supported} & \cmark & \cmark & \cmark & \cmark & \cmark \\
				\midrule
				\textbf{Different weather conditions}  & \xmark  & \cmark  & \cmark & \xmark & \cmark \\
				\midrule
				\textbf{Camera Calibration} & \xmark  & \cmark & \cmark & \xmark  & \xmark \\
				\midrule
				\textbf{Path Planning} & \cmark  & \cmark  & \cmark & \cmark & \cmark \\
				\midrule
				\textbf{Proper vehicle control dynamics}  & \cmark  & \cmark  & \cmark & \cmark & \cmark \\
				\midrule
				\textbf{3D Virtual Environment} & \cmark  & \cmark  & \cmark, OUT (Urban) & \cmark, IN \& OUT & \cmark, OUT (Urban) \\
				\midrule
				\textbf{Traffic Infrastructure} & \cmark  & \cmark & \cmark \ (including TLs, INTs, SSs, lanes)  & \cmark \ (including TLs, INTs, SSs, lanes) & \cmark \\
				\midrule
				\textbf{Simulate different dynamic objects}: & \cmark & \cmark & \cmark & \xmark & \cmark \\
				\midrule
				\textbf{2D/3D ground-truth} & \xmark & \xmark & \cmark & - & \cmark \\
				\midrule
				\textbf{Interfaces to other software} & \cmark, with MATLAB & \cmark, with MATLAB & \cmark, with ROS, Autoware & \cmark, with ROS & \cmark, with Autoware, Apollo, ROS \\
				\midrule
				\textbf{Scalability} via a server MCA & - & - & \cmark & \cmark & \cmark \\
				\midrule
				\textbf{Open Source} & \xmark & \xmark & \cmark & \cmark & \cmark \\
				\midrule
				\textbf{Stability} & \cmark & \cmark & \cmark & \cmark & \cmark \\
				\midrule
				\textbf{Portability} & \cmark & \cmark & \cmark, Windows \& Linux & \cmark, Windows \& Linux & \cmark, Windows \& Linux \\
				\midrule
				\textbf{Flexible API} & \cmark & - & \cmark & \cmark & \cmark \\
				% \hline
				\bottomrule
			\end{tabular}}
		%\end{adjustbox}
	\end{table}

In that sense, we identify that CarSim is usually connected to MATLAB/Simulink \cite{lattarulo2017complete} to simulate simple scenarios, with efficient plot functions and computation, where the user can control the vehicle models from CarSim and build their upper control algorithms in MATLAB/Simulink to do a co-simulation project, but the realism, the quality of the sensors and the complexity is limited. PreScan presents better capabilities to build realistic environments and simulate different weather conditions, unlike MATLAB and CarSim. Gazebo is quite popular as a robotic simulator, but the effort and time needed to create complex and dynamic scenes does not make it the first choice for testing self-driving technology. 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{chapter_2_related_works/carla_simulator_overview.jpg}
	\caption{CARLA simulator overview}
	\label{fig:chapter_2_related_works/carla_simulator_overview}
\end{figure}

To this end, we have two simulators as our final options: LGSVL and \ac{CARLA}. At the moment of writing this thesis, they are the most suited simulators for end-to-end testing of unique functionalities offered by autonomous vehicles, such as perception, mapping, vehicle control or localization. Most of their features, summarized in \cite{kaur2021survey} are identical (open-source, traffic generation simulation, portability, 2D/3D groundtruth, flexible API and so forth and so on), with the only difference that LGSVL does not present camera calibration to perform multi-view geometry or Simultaneous Localization and Mapping (SLAM). Regarding this, we decided to use the \ac{CARLA} simulator since the performance is very similar to LGSVL and the group had previous experience in the use of this simulator. %For a deeper understanding about how we integrate our architecture with this simulator, we refer the reader to section \ref{section:IV}.

\section{Summary}
\label{sec:2_summary}

\begin{table}[h]
	\centering
	\caption[Summary of Motion Prediction methods features]{Summary of Motion Prediction methods features. Short-term and long-term characterize prediction horizons of no more than 1-s and no less than 3-s, respectively.}
\begin{adjustbox}{max width=\textwidth}
%\begin{tabular}{|P|P|P|P|P|}
\begin{tabular}{c | c c c c }
	% Methods & Accuracy & $\begin{array}{l}\text { Prediction } \\
	%	\text { Horizon }\end{array}$ & $\begin{array}{l}\text { Computation } \\
	%	\text { Cost }\end{array}$ & Applications \\ \hline 
	\toprule
	Methods & Accuracy & Prediction Horizon & Computation Cost & Applications \\
	% \toprule
	\midrule
	
	Physics-based & $\begin{array}{l}\text { High in short-term prediction,  } \\
		\text { low in other prediction horizon }\end{array}$ & Short & Small & Colision risk analysis \\
	\midrule
	 $\begin{array}{l}\text { Classic Machine } \\
		\text { Learning-based }\end{array}$ & $\begin{array}{l}\text { Good at recognizing maneuvers but } \\
		\text { generalization ability is poor }\end{array}$ & Medium & Medium & Maneuver recognition \\
	\midrule
	$\begin{array}{l}\text { Reinforcement } \\
		\text { Learning-based }\end{array}$ & $\begin{array}{l}\text { Relatively high, prediction methods  } \\
		\text { are relatively few }\end{array}$ & Long & High & More applied in planning \\
	\midrule
	Deep Learning-based & High in considering some factors & Long & $\begin{array}{l}\text { Relatively } \\
		\text { high }\end{array}$ & $\begin{array}{l}\text { More and more applied } \\
		\text { in real-world }\end{array}$ \\ 
	\bottomrule
\end{tabular}
\label{table:2_summary_mp_methods}
\end{adjustbox}
\end{table}

In order to finish this Chapter, we perform a brief comparison between the different methods (Physics-based, Classic \ac{ML}, \ac{RL} and \ac{DL}) in terms of accuracy, prediction horizon, computation cost and applications in the \ac{AD} field. 

\begin{itemize}
	
	\item Physics-Based Methods are suitable for the movement of vehicles, which can be accurately described by kinematics or dynamics models. Given a suitable physics model, these methods can be applied to a variety of scenarios at small computational cost and in a short time but without training. However, the prediction results based on such models heavily depends on the inputs and the model selection. The inputs are closely related to human or machine drivers, influenced by the driving environment or the interactions with other participants. Therefore, without the capability to describe such factors, physics-based models are limited to short-term prediction and in static scenes. Because of its simplicity and fast response, these methods can be easily used in real applications for \acp{ADS}, such as collision risk analysis.
	
	\item Classic \ac{ML}-Based Methods, compared with physics-based methods, are able to consider more factors and its accuracy is relatively high with a longer prediction length at a higher computing cost. Most of these methods are maneuver-based methods, which predicts the trajectory with the maneuver known as a prior. However, vehicle maneuvers of human drivers are usually diverse and vary greatly in different scenarios such that the generalization ability of this approach is poor. In real applications for \acp{ADS}, such methods are used in scenarios such as lane change studies, leveraging their advantages in maneuver recognition.
	
	\item \ac{RL}-Based Methods imitate the human \ac{DM} process and obtain the reward function through learning the expert demonstration to generate the corresponding optimal driving policy. They can continuously evolve through learning and adapt to complex environments and long prediction horizons. Such methods probably generate higher accuracy trajectories than \ac{DL} methods in a longer time domain. However, most of these methods are typically computationally expensive in their recovery of an expert cost function, require long training times and its training is based on actions and episodes, in such a way its use in real-world \ac{MP} applications is not suitable, being \ac{RL} more applied to trajectory planning, taking its advantages in the \ac{DM} process.
	
	\item \ac{DL}-Based Methods can perform accurate predictions in a longer time horizon with respect to traditional methods that are only suitable for simple scenes and short-term prediction. By means of powerful neural networks, such as \acp{RNN}, \acp{CNN}, \acp{GAN}, Attention mechanisms or \acp{GNN} for feature extraction, physics-related, interaction-related and road-related factors are processed as inputs to the model. Furthermore, they can adapt to more complex environments and a longer prediction horizon. \ac{DL}-based methods require to use a large amount of data for training.
	
	Besides, with the increase of consideration factors and the increase of the number of network layers, the computing costs and time increases sharply. Such methods can naturally generate multi-modal trajectories, which is consistent with the diversity of vehicles maneuvers. In real applications for \ac{ADS}, it is necessary to reach a balance between calculation time and model complexity to ensure the real-time performance and safety of \ac{ADS}. At present, more and more real-world trials use these methods to predict the future trajectory of traffic participants.
\end{itemize}	
	
As observed in Table \ref{table:2_summary_mp_methods} and discussed in this section summarizing the different \ac{MP} algorithms, we focus this thesis on \ac{DL} methods since they are the most suitable methods for long-term prediction with a lower computation cost than \ac{RL}-based approaches, specially focusing on the ability of extracting and combining the latent spaces of the different inputs by means of \ac{SOTA} algorithms. Then, they are more suitable to model complex real-world applications, which is the final objective of this thesis.

Furthermore, the validation framework (both in terms of datasets and \ac{AD} simulator) is defined. In this thesis we choose Argoverse 1 and Argoverse 2 as databases to build our \ac{DL}-based \ac{MP} algorithms, since both are extensively used by the research community to build this kind of algorithms, and \ac{CARLA} to validate the prediction methods in a holistic way (that is, integrated with other layers such as \ac{DM} or control) in a hyper-realistic \ac{AD} simulator as a preliminary stage before implementing it in a real-world platform.